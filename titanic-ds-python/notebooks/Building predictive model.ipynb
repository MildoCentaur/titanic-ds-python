{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path of the processed data\n",
    "processed_data_path = os.path.join(os.path.pardir,'data','processed')\n",
    "train_file_path = os.path.join(processed_data_path, 'train.csv')\n",
    "test_file_path = os.path.join(processed_data_path, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_file_path, index_col='PassengerId')\n",
    "test_df = pd.read_csv(test_file_path, index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.loc[:,'Age':].values.astype('float')\n",
    "# uso ravel para convertir el dataframe en un arrego 1D \n",
    "# podria haber usado train_df['Survived'].values y obtenia el mismo resultado\n",
    "# si en lugar de tener un dataset hubiese tenido un arreglo no hubiese tenido la propiedad values\n",
    "\n",
    "y = train_df['Survived'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 (891,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 38 columns):\n",
      "Survived              891 non-null int64\n",
      "Age                   891 non-null float64\n",
      "Fare                  891 non-null float64\n",
      "FamilySize            891 non-null int64\n",
      "IsMother              891 non-null int64\n",
      "IsMale                891 non-null int64\n",
      "WCG                   891 non-null int64\n",
      "RichOldLady           891 non-null int64\n",
      "PoorOldMan            891 non-null int64\n",
      "Deck_A                891 non-null int64\n",
      "Deck_B                891 non-null int64\n",
      "Deck_C                891 non-null int64\n",
      "Deck_D                891 non-null int64\n",
      "Deck_E                891 non-null int64\n",
      "Deck_F                891 non-null int64\n",
      "Deck_G                891 non-null int64\n",
      "Deck_Z                891 non-null int64\n",
      "Pclass_1              891 non-null int64\n",
      "Pclass_2              891 non-null int64\n",
      "Pclass_3              891 non-null int64\n",
      "Title_Lady            891 non-null int64\n",
      "Title_Master          891 non-null int64\n",
      "Title_Miss            891 non-null int64\n",
      "Title_Mr              891 non-null int64\n",
      "Title_Mrs             891 non-null int64\n",
      "Title_Officer         891 non-null int64\n",
      "Title_Sir             891 non-null int64\n",
      "Fare_Bin_very_low     891 non-null int64\n",
      "Fare_Bin_low          891 non-null int64\n",
      "Fare_Bin_high         891 non-null int64\n",
      "Fare_Bin_very_high    891 non-null int64\n",
      "Embarked_C            891 non-null int64\n",
      "Embarked_Q            891 non-null int64\n",
      "Embarked_S            891 non-null int64\n",
      "AgeState_Adult        891 non-null int64\n",
      "AgeState_Child        891 non-null int64\n",
      "DeckSurvived_AGZ      891 non-null int64\n",
      "DeckSurvived_BCDEF    891 non-null int64\n",
      "dtypes: float64(2), int64(36)\n",
      "memory usage: 271.5 KB\n"
     ]
    }
   ],
   "source": [
    "print (X.shape[1], y.shape)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 37) (712,)\n",
      "(179, 37) (179,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "# uso la data de training para testear el modelo \n",
    "# el datase de test provisto por kaggle es en realidad production data \n",
    "# como no tenemos el resultodo (sobrevivio o no) no sirve para ver si el modelo funciona o no\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35.     15.2458  3.      1.      0.      1.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      1.      0.      0.\n",
      "  1.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "  0.      1.      0.      1.      0.      0.      1.      0.      1.\n",
      "  0.    ]\n"
     ]
    }
   ],
   "source": [
    "print (X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean survival in train : 0.383\n",
      "mean survival in test : 0.385\n"
     ]
    }
   ],
   "source": [
    "# average survival in train and test\n",
    "print ('mean survival in train : {0:.3f}'.format(np.mean(y_train)))\n",
    "print ('mean survival in test : {0:.3f}'.format(np.mean(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Scikit-Learn Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__\n",
    "## Tiene que ser mayor a 0.19\n",
    "#!conda update -y scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "linear_model = DummyClassifier(strategy='most_frequent', random_state=0)\n",
    "# baseline simepre va a predecir la mayoria de los casos en el dataset \n",
    "# en este caso el la mayoria de los casos son para gente que no sobrevivio \n",
    "# aprox 38% sobrevivieron y el resto no \n",
    "#random seed is the same as used when separating the dataset but it is not necesary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=0, strategy='most_frequent')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "linear_model.fit(X_train, y_train)\n",
    "#inout data y output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for baseline model : 0.61\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the performance on the test dataset\n",
    "print ('score for baseline model : {0:.2f}'.format(linear_model.score(X_test, y_test)))\n",
    "#score primero evalua el moelo con el dataset X_test,\n",
    "#luego compara el resultado con y_test que es el resultado verdadero\n",
    "\n",
    "#Este es el accuracy del modelo es decir los casos acertados sobre los casos totales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El resultado anterior quiere decir que para predecir quien murio en el accidente, utilizando un modelo de regresion lineal, se puede obtener  una certeza del 61%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peformance metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for baseline model : 0.61\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "print ('accuracy for baseline model : {0:.2f}'.format(accuracy_score(y_test, linear_model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for baseline model: \n",
      " [[110   0]\n",
      " [ 69   0]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, linear_model.predict(X_test))\n",
    "print( 'confusion matrix for baseline model: \\n {0}'.format(cm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solo predice el valor de 0 de la clase negativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## |        | Predicted       |    Predicted\n",
    "## |        | Negative        |    Positive\n",
    "## |Actual  |    110          |      0\n",
    "## |Negative| (True Negative) |  (False Positive)\n",
    "## |        |                 |\n",
    "#  |Actual  |     69          |      0\n",
    "## |Positive|                 |\n",
    "## |________|_(False Negative)|    True Positive\n",
    "\n",
    "#Accuracy = (True Positives + True Negatives) / ( TN + FN + FP + TP)  \n",
    "#Presicion = True Positive / (TP+FP) \n",
    "#Recall = True Positive/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "labels = [0, 1]\n",
    "cm = confusion_matrix(y_test, linear_model.predict(X_test), labels)\n",
    "#print(cm)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the Titanic')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for baseline model : 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mildo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# precision and recall scores\n",
    "print ('precision for baseline model : {0:.2f}'.format(precision_score(y_test, linear_model.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall for baseline model : 0.00\n"
     ]
    }
   ],
   "source": [
    "print ('recall for baseline model : {0:.2f}'.format(recall_score(y_test, linear_model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to the matrix\n",
    "test_X = test_df.values.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predictions = linear_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({'PassengerId': test_df.index, 'Survived' : predictions} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mildo/MyDocuments/datascience/titanic-ds-python/titanic-ds-python/data/external\n"
     ]
    }
   ],
   "source": [
    "submission_data_path = os.path.join(os.path.pardir,'data','external')\n",
    "submission_file_path = os.path.join(submission_data_path, '01_linear.csv')\n",
    "print (os.path.abspath(submission_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission_file(model, filename):\n",
    "    # converting to the matrix\n",
    "    test_X = test_df.values.astype('float')\n",
    "    # make predictions\n",
    "    predictions = model.predict(test_X)\n",
    "    # submission dataframe\n",
    "    df_submission = pd.DataFrame({'PassengerId': test_df.index, 'Survived' : predictions})\n",
    "    # submission file\n",
    "    submission_data_path = os.path.join(os.path.pardir,'data','external')\n",
    "    submission_file_path = os.path.join(submission_data_path, filename)\n",
    "    # write to the file\n",
    "    df_submission.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission file\n",
    "get_submission_file(linear_model, '01_linear.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "lg_model = LogisticRegression(random_state=0, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "lg_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for logistic regression - version 1 : 0.83\n"
     ]
    }
   ],
   "source": [
    "print ('score for logistic regression - version 1 : {0:.2f}'.format(lg_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression - version 1 : 0.83\n",
      "confusion matrix for logistic regression - version 1: \n",
      " [[95 15]\n",
      " [15 54]]\n",
      "precision for logistic regression - version 1 : 0.78\n",
      "recall for logistic regression - version 1 : 0.78\n"
     ]
    }
   ],
   "source": [
    "# performance metrics\n",
    "# accuracy\n",
    "print ('accuracy for logistic regression - version 1 : {0:.2f}'.format(accuracy_score(y_test, lg_model.predict(X_test))))\n",
    "# confusion matrix\n",
    "print ('confusion matrix for logistic regression - version 1: \\n {0}'.format(confusion_matrix(y_test, lg_model.predict(X_test))))\n",
    "# precision \n",
    "print ('precision for logistic regression - version 1 : {0:.2f}'.format(precision_score(y_test, lg_model.predict(X_test))))\n",
    "# precision \n",
    "print ('recall for logistic regression - version 1 : {0:.2f}'.format(recall_score(y_test, lg_model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02963478,  0.00427134, -0.50489296,  0.61100139, -0.67894805,\n",
       "         0.49390907,  0.19579302, -0.11283846,  0.3325435 , -0.33251825,\n",
       "        -0.57787989,  0.35768693,  0.93538386,  0.26457143, -0.08022686,\n",
       "        -0.08368661,  0.85122106,  0.39684463, -0.43219156,  0.24221015,\n",
       "         1.08144586,  0.38133076, -1.33738422,  0.87128127, -0.02697527,\n",
       "        -0.39603442,  0.0852801 ,  0.1678749 ,  0.21916681,  0.34355233,\n",
       "         0.41508149,  0.3553498 ,  0.04544284,  0.3106166 ,  0.50525754,\n",
       "         0.16863004,  0.64724409]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model coefficients\n",
    "lg_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission file\n",
    "get_submission_file(lg_model, '02_lr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model \n",
    "model_lr = LogisticRegression(random_state=0, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[1.0, 10.0, 50.0, 100.0, 1000.0], 'penalty' : ['l1','l2'],'class_weight' : ['balanced',None], 'solver' : ['liblinear','saga'], 'max_iter' : [100,1000,10000]}\n",
    "lg_model_grid = GridSearchCV(model_lr, param_grid=parameters, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes a couple of minutes\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "with ignore_warnings(category=ConvergenceWarning):\n",
    "    lg_model_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'max_iter': 100,\n",
       " 'penalty': 'l1',\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_model_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score : 0.83\n"
     ]
    }
   ],
   "source": [
    "print ('best score : {0:.2f}'.format(lg_model_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for logistic regression - version 2 : 0.83\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print ('score for logistic regression - version 2 : {0:.2f}'.format(lg_model_grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making third submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission file\n",
    "get_submission_file(lg_model_grid, '03_lr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Normalization and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature normalization\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[:,0].min(),X_train_scaled[:,0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.143955101825949, 3.8031127012897366)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled[:,0].min(),X_train_scaled[:,0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model after standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=0, solver='liblinear',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1.0, 10.0, 50.0, 100.0, 1000.0],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base model \n",
    "model_lr = LogisticRegression(random_state=0, solver='liblinear')\n",
    "parameters = {'C':[1.0, 10.0, 50.0, 100.0, 1000.0], 'penalty' : ['l1','l2']}#,'max_iter' : [1000,5000,10000]} #,'class_weight' : ['balanced',None], 'solver' : ['liblinear'], 'max_iter' : [1000,5000,10000]}\n",
    "lg_model_grid_scaled = GridSearchCV(model_lr, param_grid=parameters, cv=3)\n",
    "lg_model_grid_scaled.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8132022471910112"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_model_grid_scaled.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for logistic regression - version 2 : 0.84\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print ('score for logistic regression - version 2 : {0:.2f}'.format(lg_model_grid_scaled.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXyU9bn38c+VnSUEQsgCAQIkbBkUBJHFBcFIwqm1PW1Pta1Lj9ZHa/Xp8pyj1mrVWovdTrVWerBVsfXUWk/dSVgUUKsgq5IEBESFQBJ2AZU11/PHDGmMJGSSDJOE7/v1ysuZe+77N9cg5ut9/373NebuiIiINFVMtAsQEZH2RcEhIiJhUXCIiEhYFBwiIhIWBYeIiIQlLtoFnAxpaWmek5MT7TJERNqV5cuX73D3XvW3nxLBkZOTw7Jly6JdhohIu2JmHxxvuy5ViYhIWBQcIiISFgWHiIiE5ZSY4xCRjufw4cNUVFRw4MCBaJfS7iUlJZGdnU18fHyT9ldwiEi7VFFRQXJyMjk5OZhZtMtpt9ydnTt3UlFRwYABA5p0jC5ViUi7dODAAXr27KnQaCEzo2fPnmGduSk4RKTdUmi0jnD/HBUcjXjkH+/x9xUVfPjJ4WiXIiLSZig4GuDu/OXNTXz/ybcYc/c8rnzkTf66dBO7PjoU7dJEpI2oqqrikksuYdCgQQwfPpxp06axbt26Ro954IEHyM3NxczYsWNHg/vNmjWLvLw88vLymDVrVmuX3iJ2KnyR05gxY7w5d47X1DgrN++hpLSS4tIqKnZ/QmyMcdaAVIoCmUzNzyS9W1IEKhaRE1mzZg3Dhg2L2vu7OxMmTOCKK67g2muvBWDVqlXs27ePc845p8HjVq5cSY8ePZg0aRLLli0jLS3tM/vs2rWLMWPGsGzZMsyM0aNHs3z5cnr06BGxz3O8P08zW+7uY+rvq1VVjYiJMUb378Ho/j344bRhlG7ZS3FpJSWlVdz2bBm3P1fGmP49KAxkURjIpE/3TtEuWUROkgULFhAfH18bGgAjR4484XGjRo064T5z5syhoKCA1NRUAAoKCigpKeHSSy9tfsGtSMHRRGbGiOwURmSn8B9Th7Cuen9tiPzkhXJ+8kI5p2enUBjIoiiQSU5al2iXLHLKuPP5Msq37m3VMYf37saPL8pv8PXS0lJGjx7d4OsjR45k1apVzXrvLVu20Ldv39rn2dnZbNmypVljRYKCoxnMjCGZyQzJTOa7Fwxm4/b9lJRVUVJaxb0la7m3ZC1DM5OZNiIYInkZydEuWUROsuaGBgQvg9XXllaQKThawcBeXfn2pFy+PSmXzbs+Zk5ZFcWlVfx63jp+PW8dg3p1oSh0OSu/d7c29RdApCNo7MwgUvLz83nqqaciMnZ2djYLFy6sfV5RUcGkSZMi8l7NoVVVraxvameuPmcg/3vdBJb8cAp3XZxPenISDy7cwOd++xrn/WIh98xew8pNu6mp6fgLE0Q6qsmTJ3Pw4EEeeuih2m1Lly5l0aJFLR576tSpzJ07l927d7N7927mzp3L1KlTWzxua1FwRFBGtyQuH5/DX64Zx9JbL+Bn/zqCnLQuPPzae3zxwdeZeO/L3PFcGUs27uSoQkSkXTEznn76aebNm8egQYPIz8/njjvuoHfv3kDDE+X3338/2dnZVFRUcNppp3H11VcDsGzZstrHqamp3HbbbZx55pmceeaZ3H777bUT5W2BluNGwYcfH2b+mmqKS6t4Zf12Dh2pIa1rIhfmZ1AUyGTcwJ7ExyrTRRoT7eW4HY2W47ZxKZ3j+dLobL40Opv9B4+wYO02SkqreHrFFv5nySa6d46nYFgGRSMymZibRmJcbLRLFhGppeCIsq6JcVx0em8uOr03nxw6yqJ12ykJLfP92/IKkhPjmDwsnaJAJucNTqdTgkJERKJLwdGGdEqIpTCQSWEgk4NHjvL6hp0Ul1Yyt7yaZ1dtpVN8LJOG9KIwkMnkoekkJzWtd76ISGtScLRRiXGxnD80nfOHpnPP0RqWvLeL2asrmVMWnBtJiIvh3Lw0CgNZFAzLIKWzQkRETg4FRzsQFxvDxNw0JuamcdfFAZZ/sJvi0krmlFYxf8024mKM8YN6UhTI4sL8DNK6Jka7ZBHpwBQc7UxsjDF2QCpjB6Ry++eG81bFhxSXVlK8uoofPr2aHz2zmrEDUikKZDE1P5PMFDVhFJHWpTWf7ZiZMbJvd24pGsai/5jEizeezfXn57Jj/yF+/FwZ4372Ev/64D946JWNbN71cbTLFelwWrOturtz4403kpuby2mnncaKFSuOe/zy5csZMWIEubm53HjjjcdtTxJpCo4OwszI753CDy4cwvzvn8f875/LDwoGc+BwDT+dvYZzfr6Az/32VX63YAMbt++Pdrki7Z6788UvfpFJkybx7rvvUl5ezj333EN1dXWjx02cOJH58+fTv3//T20vLi5m/fr1rF+/npkzZ3Ldddcd9/jrrruOmTNn1u5bUlLSap+pqXSpqoPKTU/mhinJ3DAljw92fkRxabB/1i/mvMMv5rzDkIxkCgOZFI3IZEhGsvpniYSptduqP/vss1x++eWYGePGjWPPnj1UVlaSlZVVu09lZSV79+5l/PjxAFx++eU888wzFBUVtfDThEfBcQro37ML1543iGvPG8TWPZ9QUhrs5Hv/y+u576X1DEjrEgyRQCYj+qQoRKT9Kb4Zqla37piZI6BoeoMvt3Zb9YZaqdcNji1btpCdnf2ZfU42Bccppnf3Tvz72QP497MHsG3fAeaWVVNSWsXMVzYyY+G79OneiaLQmciovj2IiVGIiDRHuG3Vm9JKva20W1dwnMLSk5P4xrj+fGNcf3Z/dIh55dUUl1Yy6433+cNr75HRLZGp+cEbEsfmpBKn/lnSVjVyZhAprd1WPTs7m82bN9c+r6ioqG2YWHefioqKRvc5GfSbQADo0SWBfzuzL498cyzLbyvgN18dyci+3fnr0s187aEljL3nJW7+37dZtC7YlFHkVNfabdU///nP89hjj+HuLF68mJSUlE9dpgLIysoiOTmZxYsX4+489thjXHzxxS36HM2h4JDP6JYUzxdG9eG/LxvDytsLePDrZzBhUE+ef2srVzz8JmPunsf3n1zFvPJqDhw+Gu1yRaKitduqT5s2jYEDB5Kbm8u3vvUtHnzwwdpj6o41Y8YMrr76anJzcxk0aNBJnxgHtVWXMBw4fJRX1++guLSS+eXV7D1whC4JwdYoRYEszh/ai84JuvopJ4faqrcutVWXiEiKj6VgeAYFwzM4dKSGNzbupKS0krll1bzwdiWJcTFMGtKLokAWk4el001NGEU6pIgGh5kVAvcBscAf3H16vdf7AbOA7qF9bnb32WbWE3gKOBN41N2/E9q/M/A3YBBwFHje3W+O5GeQ40uIi+G8wb04b3AvfnJxDW++v6t2me+csmoSYmOYmBvsn1UwPIMeXRKiXbKItJKIBYeZxQK/AwqACmCpmT3n7uV1dvsR8KS7zzCz4cBsIAc4ANwGBEI/df3S3ReYWQLwkpkVuXtxpD6HnFhcbAwTBqUxYVAad1yUz8rNuyleHbzhcME7bxP7tDFuYGptE8b0ZPXPEmnPInnGMRbY4O4bAczsCeBioG5wONAt9DgF2Arg7h8Br5lZbt0B3f1jYEHo8SEzWwFkI21GTIwxun8qo/uncuu/DKN0y95gE8bSKn70TCm3PVvKmf1Ta793pHf3TtEuWUTCFMng6ANsrvO8Ajir3j53AHPN7AagC3BBUwc3s+7ARQQvhR3v9WuAawD69evX5KKl9ZgZI7JTGJGdwn9MHcI71fsoXh28nHXXC+Xc9UI5p/ftHrzhMJBJ/55dol2yiDRBJIPjeLcz1l/CdSnBOYxfmdl44E9mFnD3Rm8UMLM44C/A/cfOaD7zRu4zgZkQXFUVdvXSqsyMoZndGJrZje8VDGbj9v0Uh+ZEphevZXrxWoZndau9az03PTnaJYtIAyJ5H0cF0LfO82xCl6LquAp4EsDd3wCSgLQmjD0TWO/uv2mFOiUKBvbqyvXn5/L8DWfz6n+ez63ThpEUH8Ov5q3jgl+/wgW/XsSv5r5D2dYPo9I2WqQpmtNW/corr2TAgAGMHDnyU/2s2lNb9UiecSwF8sxsALAFuAT4Wr19NgFTgEfNbBjB4Nje2KBmdjfB+ZCrW71iiYq+qZ351rkD+da5A6n68ABzyqooLq3kdws28NuXN9C/Z+dQE8YsTs9WE0ZpG461Vb/iiit44okngGB/qurqagYPHtzosb/4xS/48pe//KltdduqL1myhOuuu44lS5Z85thjbdXHjRvHtGnTKCkp6Tjdcd39iJl9B5hDcKntw+5eZmZ3Acvc/TngB8BDZvY9gpexrvRQfJrZ+wQnzhPM7AvAhcBe4FZgLbAi9AvkAXf/Q6Q+h5xcmSlJXDEhhysm5LBj/0HmlgX7Z/3x1ff470Ub6Z2SxNRQiIzu34NYNWGUKGluW/WGqK16iLvPJrjEtu622+s8LgcmNnBsTgPD6jfFKSKtayJfO6sfXzurHx9+fJh5a6opKa3k8SWbeOQf75PWNZGp+RkUBbIYN1BNGE9l9755L2t3rW3VMYemDuWmsTc1+HpL2qrfeuut3HXXXUyZMoXp06eTmJiotuoirS2lczxfHp3Nl0dns//gEV5eu42S0kr+vmILjy/ZRI/O8RQMD4bIhNyeJMbFRrtkOcU1FBo/+9nPyMzM5NChQ1xzzTXce++93H777WqrLhJJXRPj+Pzpvfn86b355NBRFq3bRnFpFbNXV/HksgqSE+OYMiydwkAWk4b0IileIdLRNXZmECnNbat+7AwiMTGRb37zm/zyl78E1FZd5KTplBBLYSCL+y4ZxfLbLuDhK8dQGMhk4brtXPvn5Yy6ax7XP76C59/ayv6DR6JdrnQgzW2rXllZCQTPHp555hkCgWBzjPbUVl1nHNJhJMbFMnloBpOHZnD4aA1LNu6iuLSSOWVVvLi6koS4GM7N60VRIJMLhmWQ0llNGKX5jrVV/+53v8v06dNJSkoiJyeH3/wmeJdAQ3McX//619m+fTvuzsiRI/n9738PBNuqz549m9zcXDp37swjjzxSe0zdsWbMmMGVV17JJ598QlFRkdqqR4raqp/ajtY4y97fRXFpFXPKqqj88ABxMcaE3DSKAplcODyDnl0To12mhElt1VuX2qqL1BEbY5w1sCdnDezJ7Z8bzlsVeygpDTZhvOXvq7n16dWcNaAnRSMymZqfSUY3NWEUaYyCQ04pMTHGqH49GNWvBzcXDaVs695QiFRy+7Nl/Pi5Ms7o14OiUBPG7B6do12ySJuj4JBTlpkR6JNCoE8K/2/qENZX76M4dCZy94truPvFNZyWnVJ71/qANDVhFAEFh0itvIxk8jKSuXFKHu/v+IiSsiqKV1fy85J3+HnJOwzNTK4NkcEZXdX6RE5ZCg6R48hJ68K15w3i2vMGsWXPJ6FvN6zkvpfW85v56xmY1oWiEcEQye/dTSEipxQFh8gJ9OneiavOHsBVZw9g294DzCkPtj75/aKN/G7Bu2T36BSaE8liVN/uxKh/lnRwugFQJAzp3ZK4bFx/Hr96HEtvvYB7vzSC3PSuPPr6+3xpxutMmP4yP362lDfe3cnRmo6/1P1U15y26g888AC5ubmYGTt27Kjd3lhb9VmzZpGXl0deXh6zZs067ri7du2ioKCAvLw8CgoK2L17d+t8yONQcIg0U2qXBL56Zj8e/eZYlv2ogP/66umclp3CE0s3c+lDiznrnvnc8vfVvLJuO4ePNvrdZNIOHWurPmnSJN59913Ky8u55557qK6ubvS4iRMnMn/+fPr37/+p7XXbqs+cOZPrrrsOCAbCnXfeyZIlS3jzzTe58847jxsK06dPZ8qUKaxfv762eWKk6FKVSCtI6RTPF0dl88VR2Xx08AgL39nO7NJKnl21hb+8uYmUTvFcMCyDokAmZ+elqX9WB9DctuqjRo067vaG2qovXLiQgoICUlNTASgoKKCkpIRLL730M8cvXLgQgCuuuIJJkyZx7733NvPTNU7BIdLKuiTG8S+nZfEvp2Vx4PBRXlm3nZLSKuaWV/G/KyromhjH+UPTmRbI5LwhveicoP8MW6rqnns4uKZ126onDhtK5g9/2ODrLWmrfjwNtVVvaHt91dXVtb2tsrKy2LZtW5PfO1z6GysSQUnxsVyYn8mF+ZkcOlLD6+/uCIVINc+/tZWk+BgmDU6naEQmk4emk5yk/lkdRTihAQ23TG8rrdTrUnCInCQJcTFMGpLOpCHp3P2FGt5875/9s0rKqkiIjeHsvDQKQ/2zundOiHbJ7UZjZwaR0ty26g1pqK16dnZ27SWoY9snTZr0meMzMjJqvzGwsrKS9PT0VqutPk2Oi0RBXGwME3LT+MkXAiy+ZQpPXTuey8b3552qffznU28z+u75XPbHJTy+5AO27zsY7XLlOJrbVr0hDbVVnzp1KnPnzmX37t3s3r2buXPnMnXq1OMef2zF1axZsyLbbt3dO/zP6NGjXaQ9qKmp8bc27/bpxWv8vJ+/7P1vesFzbn7Bv/L71/3h1zb61j0fR7vENqO8vDzaJfiWLVv8K1/5ig8cONCHDx/u06ZN83Xr1rm7++mnn37cY+677z7v06ePx8bGelZWll911VXuHvx3/+1vf9sHDhzogUDAly5dWnvMH//4Rx80aJAPGjTIH3744drtV111Ve1+O3bs8MmTJ3tubq5PnjzZd+7cGdZnOd6fJ7DMj/M7VW3VRdood2dtVbB/VklpJeuq9wMwsm93poXuWu+beuo2YVRb9daltuoiHYCZMSyrG8OyuvH9gsG8u31/bSffe2av5Z7Za8nv3a32rvXc9K7RLllOEQoOkXZiUK+uXH9+Ltefn8vmXR9TXFpJcWkVv5y7jl/OXUdeeleKApkUjchiaGZy1FfeSMel4BBph/qmduaacwdxzbmDqPzwE+aE2sE/sGAD97+8gZyenSkMZFEUyOS07BSFiLQqBYdIO5eV0okrJw7gyokD2L7vIPPKqykureQPr27k94vepU/3TkzNz6RoRCaj+/VQE0ZpMQWHSAfSKzmRr53Vj6+d1Y89Hx9iXnk1JaVV/HnxBzz8j/folZxIYX4mRYFMxg5IJS5WK/IlfAoOkQ6qe+cEvjKmL18Z05d9Bw7z8tptlJRW8bflm/nT4g9I7ZJAwbAMCkdkMnFQGglxChFpGv1NETkFJCfFc/HIPsz4xmhW3FbAjK+fwdm5aby4upJvPrKU0XfP43t/XcWcsioOHD4a7XLbjWi3VV++fDkjRowgNzeXG2+88bjtSRobt9mOd3NHR/vRDYAix/fJoSM+v7zKf/DkKj/tjjne/6YXfNhtxf7tx5f7829t8f0HDke7xAZF+wbAmpoaHzdunM+YMaN228qVK/2VV15p9LgVK1b4e++95/379/ft27fXbn/xxRe9sLDQa2pq/I033vCxY8e6u/vOnTt9wIABvnPnTt+1a5cPGDDAd+3a5e7uZ555pr/++uteU1PjhYWFPnv27M+8X0Pj1hfODYC6VCVyCkuKj2XKsAymDMvg8NEaFm/cSXFpFXPLqnjx7UoS42I4d3AvigKZTBmWQUonNWE8Jtpt1SdNmsTevXsZP348AJdffjnPPPMMRUVFTRr3WCfd5lBwiAgA8bExnJPXi3PyevGTiwMsfX9X6LvWq5hXXk18rDFhUBrTRmRSMDyT1C5tpwnjq0+uY8fm/a06Zlrfrpzzb4MbfD3abdW3bNlCdnb2Z7Y3dVwFh4i0qtgYY9zAnowb2JPbPzecVRV7au9av+l/V/PDp0s5a0AqRYFMpuZnkt4tKdoltzmRbqve0PamjtsSCg4RaVRMjHFGvx6c0a8HtxQNpWzr3tq71m97tozbnytjdL8eFIbuWu/TvdNJr7GxM4NIiXZb9ezsbCoqKj6zf1PHbQmtqhKRJjMzAn1S+I+pQ3np++cx93vn8t0pg9l/8Ah3v7iGidNf5uIHXmPGwnd5f8dH0S43oqLdVj0rK4vk5GQWL16Mu/PYY48dt5V6Q+O2yPFmzDvaj1ZViUTexu37/cEFG/yi377q/W96wfvf9IJP/a9F/pt563xd1d5Wf79or6pyj35b9aVLl3p+fr4PHDjQr7/+eq+pqXF39xkzZtSu9mps3LrUVr0etVUXObkqdn9cO7G+fNNu3GFQry4UBbIoDGSS37tbi6+zq61661JbdRGJquwenbn6nIFcfc5Atu09wJyyYBPGBxdu4IEFG+ib2qk2REZmd1f/rHZGwSEiEZXeLYnLxudw2fgcdu4/1oSxikf+8R4zX9lIZrek4MR6IJMxOanEKkTaPAWHiJw0PbsmcsnYflwyth8ffnKYl9YEQ+R/3tzEo6+/T1rXBC4MNWEcN7An8SdowujuahnfCsKdsohocJhZIXAfEAv8wd2n13u9HzAL6B7a52Z3n21mPYGngDOBR939O3WOGQ08CnQCZgP/10+FiRqRDialUzz/ekY2/3pGNh8dPMKCd7ZRvLqKZ1Zu4X+WbKJ753guGJZBUSCTs/PSSIyL/dTxSUlJ7Ny5k549eyo8WsDd2blzJ0lJTb8X54ST42aWAdwD9Hb3IjMbDox39z+e4LhYYB1QAFQAS4FL3b28zj4zgZXuPiM07mx3zzGzLsAoIAAE6gXHm8D/BRYTDI773b24sVo0OS7Sfhw4fJRF67ZTUlrF/DXV7DtwhOTEOCYPS6cokMl5g9PplBDL4cOHqaio4MCBA9Euud1LSkoiOzub+PhPt5RpyeT4o8AjwK2h5+uAvwKNBgcwFtjg7htDBTwBXAyU19nHgW6hxynAVgB3/wh4zcxy632ILKCbu78Rev4Y8AWg0eAQkfYjKT6WqfnBO9IPHanhH+/uoGR1FXPLq3h21VY6xccyaUgvCgOZTB6aTXKS+medbE0JjjR3f9LMbgFw9yNm1pS+y32AzXWeVwBn1dvnDmCumd0AdAEuaMKYFXWeV4S2fYaZXQNcA9CvX78mlCsibU1CXAznD0nn/CHp/PRogCXv7aK4tJI5ZcG5kYTYGM7JS6NoRBYFwzJI6awQORmaEhwfheYcHMDMxgEfNuG44110rH9d7FKCcxi/MrPxwJ/MLODuNS0YM7jRfSYwE4KXqppQr4i0YXGxMUzMTWNibhp3fj7Aik27KV5dRUlpJS+t3UZcjDF+UE+KAllcmJ9BWtfEaJfcYTUlOL4PPAcMMrN/AL2ALzfhuAqgb53n2YQuRdVxFVAI4O5vmFkSkAZsa2TM7DrPjzemiHRwsTHGmTmpnJmTym2fG8bbFR9SHGrC+MOnV/OjZ1ZzZk6wCWNhIIvMFDVhbE2NBoeZxQBJwHnAEIL/x/+Oux9uwthLgTwzGwBsAS4BvlZvn03AFOBRMxsWeq/tDQ3o7pVmti901rMEuBz4bRNqEZEOysw4vW93Tu/bnZsKh7Cmch8loSaMdzxfzh3Pl3NGv+61Nxz2Te0c7ZLbvaasqnrD3cc3a3CzacBvCC61fdjdf2pmdxHsf/JcaCXVQ0BXgpec/tPd54aOfZ/gxHkCsAe40N3LzWwM/1yOWwzccKLluFpVJXJq2rBtf22IlG3dC0CgT7faEBnUq2uUK2zbGlpV1ZTguBN4G/h7e71fQsEhIpt2flzbDn7V5j0ADM7oSlEgi6IRmQzJSNb9IPW0JDj2EVzxdBT4hODlKnf3bo0e2IYoOESkrq17Pqntn7X0/V24w4C0LrWtT0b0SVGI0ILg6AgUHCLSkO37DjK3vIri1VW8sXEnR2ucPt07URjIZNqITEb17XHKNmFsUXCY2eeBc0NPF7r7C61cX0QpOESkKXZ/dIh5a6opKa3itfU7OHS0hoxuiUzNz6QwkMnYnFTiTtA/qyNpyaWq6QR7Rj0e2nQpsNzdb271KiNEwSEi4dp74DAL1gb7Zy1ct40Dh2tI7ZLAhcMzKAxkMmFQGglxHTtEWhIcbwMjj92UF+pBtdLdT4tIpRGg4BCRlvj40BEWvbOd2aVVvLymmo8OHaVbUhwXDM+gKJDFOXlpJMXHnnigdqalX+TUHdgVepzSalWJiLQDnRPiKBqRRdGILA4cPspr63dQXFrFvPIq/r5iC10SYjl/aDpFgSwmDelFl8SO/Y0VTfl0PwNWmtkCgiuqzgVuiWhVIiJtVFJ8LBcMz+CC4RkcPjqCN97dSXFpFXPLqnjh7UoS42I4b3AvikZkMmVYBt06YBPGpk6OZxGc5zBgibtXRbqw1qRLVSISaUdrnDff20VJaSUlZVVU7z1IfKxxdm4aRYEsCoZn0KNLQrTLDEtL5ji+CLzs7h+GnncHJrn7MxGpNAIUHCJyMtXUOCs376m9a71i9yfExhjjBqZSGMhian4G6cltv39WS4JjlbuPrLdtpbuPauUaI0bBISLR4u6UbtlLcWklJaVVbNzxEWYwpn+P2tYnvbt3inaZx9WiVVX1V1CZ2Wp3H9HKNUaMgkNE2gJ3Z131/toQWVu1D4DT+3anKHTXev+eXaJc5T+1JDgeJthk8HcEGxHeAPRw9ysjUGdEKDhEpC3auH0/JWXBu9ZXbwl+zdGwrG61IZKXkRzV+loSHF2A2wh+O58Bc4G7Q1/v2i4oOESkrdu86+Pa/lnLP9gNQG5619B3imQyPKvbSe+f1Sq9qkI3/3Vx972tWVykKThEpD2p3nsgGCKrq1jy3k5qHPqldq4NkZF9u5+UEGnJGcf/ANcS7I67nOANgL92919EotBIUHCISHu1c/9B5pYHv2P99Q07OFLj9E5JYmogk6JAFqP79yA2Qk0YW7yqysy+DowGbiLYq0otR0RETqIPPz7M/DXBEHll/XYOHakhrWsiU/ODrU/GDWzdJowtaTkSb2bxwBeAB9z9sJl1/F7sIiJtTErneL40Opsvjc5m/8EjLFi7jZLSYNuTx5dsonvneAqGZTBtRBYTcnuSGBeZ/llNCY7/Bt4H3gJeMbP+QLua4xAR6Wi6JsZx0em9uej03nxy6CiL1m0P3rVeWsXflleQnF/NSI0AAAsQSURBVBjHlGHp/Pii/Fa/Y/2EweHu9wP3H3tuZpuA81u1ChERabZOCbEUhibODx45yusbdlJcWsnyD3aTnNT6DRfDHjH0veNHWr0SERFpscS4YKfe84em4+4RWX3Vsb+FRETkFBapJbsKDhERCUuTLlWZ2QQgp+7+7v5YhGoSEZE27ITBYWZ/AgYBqwjeBAjBnlUKDhGRU1BTzjjGAMM9nN4kIiLSYTVljqMUyIx0ISIi0j405YwjDSg3szeBg8c2uvvnI1aViIi0WU0JjjsiXYSIiLQfTblzfNHJKERERNqHE85xmNk4M1tqZvvN7JCZHTUz9aoSETlFNWVy/AHgUmA90Am4OrRNREROQU26AdDdN5hZrLsfBR4xs9cjXJeIiLRRTQmOj80sAVhlZj8HKoEukS1LRETaqqZcqrostN93gI+AvsCXIlmUiIi0XU1ZVfWBmXUCstz9zpNQk4iItGFNWVV1EcE+VSWh5yPN7LlIFyYiIm1TUy5V3QGMBfYAuPsqgp1yRUTkFNSU4Dji7h9GvBIREWkXmtTk0My+BsSaWZ6Z/RZo0nJcMys0s3fMbIOZ3Xyc1/uZ2QIzW2lmb5vZtDqv3RI67h0zm1pn+/fMrMzMSs3sL2aW1JRaRESkdTQlOG4A8gk2OPwLsBf47okOMrNY4HdAETAcuNTMhtfb7UfAk+4+CrgEeDB07PDQ83ygEHjQzGLNrA9wIzDG3QNAbGg/ERE5SZqyqupj4NbQTzjGAhvcfSOAmT0BXAyU1x0e6BZ6nAJsDT2+GHjC3Q8C75nZhtB4m0I1dzKzw0DnOseIiMhJ0GBwnGjlVBPaqvcBNtd5XgGcVW+fO4C5ZnYDwZsKL6hz7OJ6x/Zx9zfM7JcEA+QTYK67z22g/muAawD69et3glJFRKSpGjvjGE/wF/9fgCWAhTn28fav/y2ClwKPuvuvzGw88CczCzR0rJn1IHg2MoDgKq+/mdk33P3Pn9nZfSYwE2DMmDH69kIRkVbS2BxHJvBDIADcBxQAO9x9URNbrVcQvMv8mGw+e1npKuBJAHd/A0gi+MVRDR17AfCeu29398PA34EJTahFRERaSYPB4e5H3b3E3a8AxgEbgIWhy0pNsRTIM7MBoV5XlwD1L39tAqYAmNkwgsGxPbTfJWaWaGYDgDzgzdD+48yss5lZ6Ng1TaxHRERaQaOT42aWCPwLwUtKOcD9BP8v/4Tc/YiZfQeYQ3D108PuXmZmdwHL3P054AfAQ2b2PYKXsa50dwfKzOxJghPpR4DrQ515l5jZU8CK0PaVhC5HiYjIyWHB39PHecFsFsHLVMUEVziVnszCWtOYMWN82bJl0S5DRKRdMbPl7j6m/vbGzjguI9gNdzBwY/DKUHAswN29W0MHiohIx9VgcLh7U24OFBGRU4zCQUREwqLgEBGRsCg4REQkLAoOEREJi4JDRETCouAQEZGwKDhERCQsCg4REQmLgkNERMKi4BARkbAoOEREJCwKDhERCYuCQ0REwqLgEBGRsCg4REQkLAoOEREJi4JDRETCouAQEZGwKDhERCQsCg4REQmLgkNERMKi4BARkbAoOEREJCwKDhERCYuCQ0REwqLgEBGRsCg4REQkLAoOEREJi4JDRETCouAQEZGwKDhERCQsCg4REQmLgkNERMKi4BARkbAoOEREJCwKDhERCUtEg8PMCs3sHTPbYGY3H+f1fma2wMxWmtnbZjatzmu3hI57x8ym1tne3cyeMrO1ZrbGzMZH8jOIiMinxUVqYDOLBX4HFAAVwFIze87dy+vs9iPgSXefYWbDgdlATujxJUA+0BuYb2aD3f0ocB9Q4u5fNrMEoHOkPoOIiHxWJM84xgIb3H2jux8CngAurrePA91Cj1OAraHHFwNPuPtBd38P2ACMNbNuwLnAHwHc/ZC774ngZxARkXoiGRx9gM11nleEttV1B/ANM6sgeLZxwwmOHQhsBx4JXd76g5l1Od6bm9k1ZrbMzJZt3769xR9GRESCIhkcdpxtXu/5pcCj7p4NTAP+ZGYxjRwbB5wBzHD3UcBHwGfmTgDcfaa7j3H3Mb169WruZxARkXoiGRwVQN86z7P556WoY64CngRw9zeAJCCtkWMrgAp3XxLa/hTBIBERkZMkksGxFMgzswGhSexLgOfq7bMJmAJgZsMIBsf20H6XmFmimQ0A8oA33b0K2GxmQ0LHTwHKERGRkyZiq6rc/YiZfQeYA8QCD7t7mZndBSxz9+eAHwAPmdn3CF6KutLdHSgzsycJhsIR4PrQiioIzoM8HgqjjcA3I/UZRETksyz4e7pjGzNmjC9btizaZYiItCtmttzdx9TfrjvHRUQkLAoOEREJi4JDRETCouAQEZGwKDhERCQsCg4REQmLgkNERMKi4BARkbAoOEREJCwKDhERCYuCQ0REwqLgEBGRsCg4REQkLAoOEREJi4JDRETCouAQEZGwKDhERCQsCg4REQmLgkNERMKi4BARkbAoOEREJCwKDhERCUtctAtoyx67+iccPpwe7TJERJolPn4bl//htlYfV2ccIiISFp1xNCISSS0i0t7pjENERMKi4BARkbAoOEREJCwKDhERCYuCQ0REwqLgEBGRsCg4REQkLAoOEREJi7l7tGuIODPbDnzQzMPTgB2tWI6IyMnS0t9f/d29V/2Np0RwtISZLXP3MdGuQ0QkXJH6/aVLVSIiEhYFh4iIhEXBcWIzo12AiEgzReT3l+Y4REQkLDrjEBGRsCg4REQkLAqOesxsf53HJWa2x8xeiGZNIiJNdex3mJmNNLM3zKzMzN42s6+22ntojuPTzGy/u3cNPZ4CdAb+j7t/LrqViYic2LHfYWY2GHB3X29mvYHlwDB339PS99AZRyPc/SVgX7TrEBEJl7uvc/f1ocdbgW3AZ+4Cbw4Fh4hIB2dmY4EE4N3WGC+uNQYREZG2ycyygD8BV7h7TWuMqTMOEZEOysy6AS8CP3L3xa01roJDRKQDMrME4GngMXf/W2uOreBohJm9CvwNmGJmFWY2Ndo1iYg00b8B5wJXmtmq0M/I1hhYy3FFRCQsOuMQEZGwKDhERCQsCg4REQmLgkNERMKi4BARkbAoOETaIDPLMbPS0OORZjYt2jWJHKPgEGn7RgIKDmkzFBwizRA6I1hrZrNC33XwlJl1NrPRZrbIzJab2ZxQnyDMbKGZ3Wtmb5rZOjM7p844r5rZitDPhHrvkwDcBXw1dAPXV81svZn1Cr0eY2YbzCztZP8ZyKlLwSHSfEOAme5+GrAXuB74LfBldx8NPAz8tM7+ce4+Fvgu8OPQtm1AgbufAXwVuL/uG7j7IeB24K/uPtLd/wr8Gfh6aJcLgLfcfUckPqDI8ag7rkjzbXb3f4Qe/xn4IRAA5pkZQCxQWWf/v4f+uRzICT2OBx4ItYI4Cgxuwvs+DDwL/Ab4d+CR5n8EkfApOESar36/nn1AmbuPb2D/g6F/HuWf/+19D6gGTid4BeDACd/UfbOZVZvZZOAs/nn2IXJS6FKVSPP1M7NjIXEpsBjodWybmcWbWf4JxkgBKkPfk3AZwbOU+vYByfW2/YHgWc6T7n60uR9ApDkUHCLNtwa4wszeBlIJzW8A95rZW8AqYEIjxwM8GBpjMcHLVB8dZ58FwPBjk+Ohbc8BXdFlKokCdccVaQYzywFecPdAlN5/DPBf7n5ONN5fTm2a4xBpZ8zsZuA6NLchUaIzDhERCYvmOEREJCwKDhERCYuCQ0REwqLgEBGRsCg4REQkLP8fkF2ddI5Vhm0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = lg_model_grid_scaled.cv_results_['mean_test_score']\n",
    "scores = np.array(scores).reshape(len(parameters['C']), len(parameters['penalty']))\n",
    "\n",
    "for ind, i in enumerate(parameters['C']):\n",
    "    plt.plot(parameters['penalty'], scores[ind], label='C: ' + str(i))\n",
    "plt.legend()\n",
    "plt.xlabel('penalty')\n",
    "plt.ylabel('Mean score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Persistence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle library\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the file paths\n",
    "model_file_path = os.path.join(os.path.pardir,'models','lr_model.pkl')\n",
    "scaler_file_path = os.path.join(os.path.pardir,'models','lr_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the files to write \n",
    "model_file_pickle = open(model_file_path, 'wb')\n",
    "scaler_file_pickle = open(scaler_file_path, 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist the model and scaler\n",
    "pickle.dump(lg_model_grid_scaled, model_file_pickle)\n",
    "pickle.dump(scaler, scaler_file_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the file\n",
    "model_file_pickle.close()\n",
    "scaler_file_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the persisted file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open files in read mode\n",
    "model_file_pickle = open(model_file_path, 'rb')\n",
    "scaler_file_pickle = open(scaler_file_path, 'rb')\n",
    "# load files\n",
    "clf_loaded = pickle.load(model_file_pickle)\n",
    "scaler_loaded = pickle.load(scaler_file_pickle)\n",
    "# close files\n",
    "model_file_pickle.close()\n",
    "scaler_file_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=0, solver='liblinear',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1.0, 10.0, 50.0, 100.0, 1000.0],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for persisted logistic regression : 0.84\n"
     ]
    }
   ],
   "source": [
    "# transform the test data using loaded scaler object\n",
    "X_test_scaled = scaler_loaded.transform(X_test)\n",
    "# calculate the score using loaded model object \n",
    "print ('score for persisted logistic regression : {0:.2f}'.format(clf_loaded.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Third Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission_file_with_standardization(model,filename, scaler):\n",
    "    # converting to the matrix\n",
    "    test_X = test_df.values.astype('float')\n",
    "    # standardization\n",
    "    if (scaler!=None):\n",
    "        test_X = scaler.transform(test_X)\n",
    "    # make predictions\n",
    "    predictions = model.predict(test_X)\n",
    "    # submission dataframe\n",
    "    df_submission = pd.DataFrame({'PassengerId': test_df.index, 'Survived' : predictions})\n",
    "    # submission file\n",
    "    submission_data_path = os.path.join(os.path.pardir,'data','external')\n",
    "    submission_file_path = os.path.join(submission_data_path, filename)\n",
    "    # write to the file\n",
    "    df_submission.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission file\n",
    "get_submission_file_with_standardization(lg_model_grid_scaled, '04_lr.csv', scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for random forest - version 1 : 0.82\n"
     ]
    }
   ],
   "source": [
    "random_forest_scaled = RandomForestClassifier(random_state=0,n_estimators=10)\n",
    "random_forest_scaled.fit(X_train_scaled, y_train)\n",
    "# evaluate model\n",
    "print ('score for random forest - version 1 : {0:.2f}'.format(random_forest_scaled.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for random forest - version 1 : 0.82\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=0,n_estimators=10)\n",
    "random_forest.fit(X_train, y_train)\n",
    "# evaluate model\n",
    "print ('score for random forest - version 1 : {0:.2f}'.format(random_forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission file\n",
    "get_submission_file_with_standardization(random_forest_scaled, '05_rf_scaled.csv', scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission file\n",
    "get_submission_file_with_standardization(random_forest, '05_rf_notscaled.csv', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for random fores no scaled model : 0.80\n",
      "recall for random fores no scaled model : 0.70\n"
     ]
    }
   ],
   "source": [
    "print ('precision for random fores no scaled model : {0:.2f}'.format(precision_score(y_test, random_forest.predict(X_test))))\n",
    "\n",
    "print ('recall for random fores no scaled model : {0:.2f}'.format(recall_score(y_test, random_forest.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for random fores  scaled model : 0.80\n",
      "recall for random fores  scaled model : 0.70\n"
     ]
    }
   ],
   "source": [
    "print ('precision for random fores  scaled model : {0:.2f}'.format(precision_score(y_test, random_forest_scaled.predict(X_test_scaled))))\n",
    "\n",
    "print ('recall for random fores  scaled model : {0:.2f}'.format(recall_score(y_test, random_forest_scaled.predict(X_test_scaled))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators':[50, 100, 200,1000], \n",
    "              'min_samples_leaf':[1, 5,10,50],\n",
    "              'max_features' : ('auto','sqrt','log2'),\n",
    "               }\n",
    "rf = RandomForestClassifier(random_state=0, oob_score=True)\n",
    "rf_grid = GridSearchCV(rf, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=True, random_state=0,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_features': ('auto', 'sqrt', 'log2'),\n",
       "                         'min_samples_leaf': [1, 5, 10, 50],\n",
       "                         'n_estimators': [50, 100, 200, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=True, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score for random forest : 0.84\n",
      "rf_grid.best_estimator_: 0.84\n",
      "rf_grid.score : 0.84\n",
      "rf_grid_scaled.score : 0.84\n"
     ]
    }
   ],
   "source": [
    "# best score\n",
    "print ('best score for random forest : {0:.2f}'.format(rf_grid.best_score_))\n",
    "\n",
    "print ('rf_grid.best_estimator_: {0:.2f}'.format(rf_grid.best_estimator_.score(X_test, y_test)))\n",
    "print ('rf_grid.score : {0:.2f}'.format(rf_grid.score(X_test, y_test)))\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, oob_score=True)\n",
    "rf_grid_scaled = GridSearchCV(rf, parameters, cv=5)\n",
    "rf_grid_scaled.fit(X_train_scaled, y_train)\n",
    "print ('rf_grid_scaled.score : {0:.2f}'.format(rf_grid_scaled.score(X_test_scaled, y_test)))\n",
    "get_submission_file_with_standardization(rf_grid_scaled, '05_rf_hp_tunning_scaled.csv', scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission file\n",
    "get_submission_file(rf_grid, '05_rf_hp_tunning.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Metrics , Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=0, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8324022346368715"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8231225296442688"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Final Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_df.values.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 2)\n"
     ]
    }
   ],
   "source": [
    "print (predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm\n",
    "#!brew install libomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mildo/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search are: {'learning_rate': 0.355, 'n_estimators': 8, 'num_leaves': 25}\n",
      "Best parameters found by grid search are: 0.8441011235955056\n"
     ]
    }
   ],
   "source": [
    "estimator = LGBMClassifier(random_state=0)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [ 0.345,0.35,0.355,0.36],\n",
    "    'n_estimators': [8,10,20],\n",
    "    'num_leaves' : [25] \n",
    "}\n",
    "\n",
    "lgbm = GridSearchCV(estimator, param_grid, cv=3)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters found by grid search are:', lgbm.best_params_)\n",
    "print('Best parameters found by grid search are:', lgbm.best_score_)\n",
    "\n",
    "y_pred = lgbm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of prediction is: 0.4025061157105039\n"
     ]
    }
   ],
   "source": [
    "#{'learning_rate': 0.3, 'n_estimators': 10, 'num_leaves': 30} -->102+51\n",
    "#{'learning_rate': 0.35, 'n_estimators': 9, 'num_leaves': 28} --> 104+50\n",
    "#{'learning_rate': 0.35, 'n_estimators': 9, 'num_leaves': 26} --> 104+50\n",
    "#{'learning_rate': 0.35, 'n_estimators': 9, 'num_leaves': 25} --> 102 +52\n",
    "#{'learning_rate': 0.35, 'n_estimators': 9, 'num_leaves': 24} --> 103 +50\n",
    "model_lgbm = LGBMClassifier( random_state=0, learning_rate= 0.355, n_estimators = 8, num_leaves= 25)\n",
    "\n",
    "model_lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_lgbm.predict(X_test)\n",
    "\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100  10]\n",
      " [ 19  50]]\n",
      "150\n",
      "precision for random fores no scaled model : 0.83\n",
      "recall for random fores no scaled model : 0.72\n",
      "score for random forest - version 1 : 0.86\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "cm = confusion_matrix(y_test, model_lgbm.predict(X_test), labels=labels)\n",
    "print (cm)\n",
    "print(cm[0,0] + cm[1,1])\n",
    "print ('precision for random fores no scaled model : {0:.2f}'.format(precision_score(y_test, model_lgbm.predict(X_test))))\n",
    "\n",
    "print ('recall for random fores no scaled model : {0:.2f}'.format(recall_score(y_test, model_lgbm.predict(X_test))))\n",
    "# evaluate model\n",
    "\n",
    "print ('score for random forest - version 1 : {0:.2f}'.format((104+50)/(19+6+104+50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search are: {'learning_rate': 0.3, 'n_estimators': 10, 'num_leaves': 30}\n"
     ]
    }
   ],
   "source": [
    "estimator = LGBMClassifier(random_state=0)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [ 0.1,0.15,0.2,0.25,0.3],\n",
    "    'n_estimators': [10,20,30,40,50,70,100,130,150],\n",
    "    'num_leaves' : [30,50,70,100] \n",
    "}\n",
    "\n",
    "lgbm_scaled = GridSearchCV(estimator, param_grid, cv=3)\n",
    "lgbm_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Best parameters found by grid search are:', lgbm.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of prediction is: 0.38111861230861543\n",
      "[[102   8]\n",
      " [ 18  51]]\n",
      "precision for random fores no scaled model : 0.86\n",
      "recall for random fores no scaled model : 0.74\n",
      "score for random forest - version 1 : 0.85\n"
     ]
    }
   ],
   "source": [
    "model_lgbm_scaled = LGBMClassifier( random_state=0, learning_rate = 0.3, n_estimators = 10, num_leaves = 30)\n",
    "\n",
    "model_lgbm_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model_lgbm_scaled.predict(X_test_scaled)\n",
    "\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "\n",
    "labels = [0, 1]\n",
    "cm = confusion_matrix(y_test, model_lgbm_scaled.predict(X_test_scaled), labels=labels)\n",
    "print (cm)\n",
    "\n",
    "print ('precision for random fores no scaled model : {0:.2f}'.format(precision_score(y_test, model_lgbm_scaled.predict(X_test_scaled))))\n",
    "\n",
    "print ('recall for random fores no scaled model : {0:.2f}'.format(recall_score(y_test, model_lgbm_scaled.predict(X_test_scaled))))\n",
    "# evaluate model\n",
    "\n",
    "print ('score for random forest - version 1 : {0:.2f}'.format((102+51)/(18+8+102+51)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission file\n",
    "get_submission_file(model_lgbm, '06_lgbm_hp_tunning.csv')\n",
    "get_submission_file_with_standardization(model_lgbm_scaled, '06_lgbm_hp_tunning_scaled.csv', scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC   C-Support Vector Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['C', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose'])\n",
      "SVC: 0.80\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "[[94 16]\n",
      " [20 49]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "estimador = SVC(random_state=0)\n",
    "print (estimador.get_params().keys())\n",
    "parameters = {  'kernel': ['rbf'],\n",
    "    'C':     [7,8,9,10,20,25,30,70,100],\n",
    "    'gamma': [0.0001,0.001,0.008,0.009,0.01,0.011],\n",
    "    'probability': [True]\n",
    "}\n",
    "svc_grid = GridSearchCV(estimator=estimador, param_grid=parameters, cv=5, iid=False)\n",
    "svc_grid.fit(X_train, y_train)\n",
    "score = svc_grid.score(X_test, y_test)\n",
    "print('%s: %.2f' % (estimador.__class__.__name__, score))\n",
    "print(svc_grid.best_params_)\n",
    "# get submission file\n",
    "get_submission_file(svc_grid, '07_svc_hp_tunning.csv')\n",
    "labels = [0, 1]\n",
    "cm = confusion_matrix(y_test, svc_grid.predict(X_test), labels=labels)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "estimador = GradientBoostingClassifier(random_state=0,n_estimators=50)\n",
    "estimador.get_params().keys()\n",
    "parameters = {'learning_rate': np.logspace(-4, 0, 10)}\n",
    "gradientBoosting = GridSearchCV(estimator=estimador, param_grid=parameters, cv=5, iid=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV: 0.82\n"
     ]
    }
   ],
   "source": [
    "gradientBoosting.fit(X_train, y_train)\n",
    "score = gradientBoosting.score(X_test, y_test)\n",
    "print('%s: %.2f' % (gradientBoosting.__class__.__name__, score))\n",
    "get_submission_file(gradientBoosting, '08_GradientBoosting_hp_tunning.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "network = MLPClassifier( hidden_layer_sizes=(10,5, 2), random_state=0,max_iter=800)\n",
    "print (network.get_params().keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier: 0.61\n"
     ]
    }
   ],
   "source": [
    "network.fit(X_train, y_train)\n",
    "score = network.score(X_test, y_test)\n",
    "print('%s: %.2f' % (network.__class__.__name__, score))\n",
    "get_submission_file(network, '09_deepNN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "vc = VotingClassifier(estimators=[('network', network), ('gbc', gradientBoosting), ('svm', svc_grid),('model_lgbm_scaled', model_lgbm_scaled), ('model_lgbm', model_lgbm), ('rf_grid_scaled', rf_grid_scaled)], voting='soft', n_jobs=4, weights=[3,1,2,3,1,2])\n",
    "vc = vc.fit(X_train, y_train)\n",
    "score = vc.score(X_test, y_test)\n",
    "print('%s: %.2f' % (vc.__class__.__name__, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for baseline model : 0.61\n",
      "score for lg_model     \t\t    : 0.75\n",
      "score for lg_model_grid \t\t: 0.75\n",
      "score for lg_model_grid_scaled  : 0.61\n",
      "score for random_forest_scaled  : 0.64\n",
      "score for random_forest    \t    : 0.82\n",
      "rf_grid.best_estimator_: 0.84\n",
      "rf_grid_scaled.score : 0.63\n",
      "model_lgbm\n",
      "[[102   8]\n",
      " [ 18  51]]\n",
      "model_lgbm\n",
      "[[102   8]\n",
      " [ 18  51]]\n",
      "svc_grid\n",
      "[[94 16]\n",
      " [20 49]]\n",
      "gradientBoosting\n",
      "GridSearchCV: 0.82\n",
      "network\n",
      "MLPClassifier: 0.61\n"
     ]
    }
   ],
   "source": [
    "print ('score for baseline model : {0:.2f}'.format(linear_model.score(X_test, y_test)))\n",
    "print ('score for lg_model     \t\t    : {0:.2f}'.format(lg_model.score(X_test_scaled, y_test)))\n",
    "print ('score for lg_model_grid \t\t: {0:.2f}'.format(lg_model_grid.score(X_test_scaled, y_test)))\n",
    "print ('score for lg_model_grid_scaled  : {0:.2f}'.format(lg_model_grid_scaled.score(X_test_scaled, y_test)))\n",
    "print ('score for random_forest_scaled  : {0:.2f}'.format(random_forest_scaled.score(X_test, y_test)))\n",
    "print ('score for random_forest    \t    : {0:.2f}'.format(random_forest.score(X_test, y_test)))\n",
    "print ('rf_grid.best_estimator_: {0:.2f}'.format(rf_grid.best_estimator_.score(X_test, y_test)))\n",
    "print ('rf_grid_scaled.score : {0:.2f}'.format(rf_grid_scaled.score(X_test_scaled, y_test)))\n",
    "print ('model_lgbm')\n",
    "labels = [0, 1]\n",
    "cm = confusion_matrix(y_test, model_lgbm.predict(X_test), labels=labels)\n",
    "print (cm)\n",
    "print ('model_lgbm')\n",
    "labels = [0, 1]\n",
    "cm = confusion_matrix(y_test, model_lgbm_scaled.predict(X_test_scaled), labels=labels)\n",
    "print (cm)\n",
    "print ('svc_grid')\n",
    "labels = [0, 1]\n",
    "cm = confusion_matrix(y_test, svc_grid.predict(X_test), labels=labels)\n",
    "print (cm)\n",
    "print ('gradientBoosting')\n",
    "print('%s: %.2f' % (gradientBoosting.__class__.__name__, gradientBoosting.score(X_test, y_test))) \n",
    "print ('network')\n",
    "score = network.score(X_test, y_test)\n",
    "print('%s: %.2f' % (network.__class__.__name__, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
